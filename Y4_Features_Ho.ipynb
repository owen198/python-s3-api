{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://10.100.0.6:8080\n",
      "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (2.49.0)\n",
      "Looking in indexes: http://10.100.0.6:8080\n",
      "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (3.10.1)\n",
      "Looking in indexes: http://10.100.0.6:8080\n",
      "Requirement already satisfied: pymssql in /usr/local/lib/python3.6/dist-packages (2.1.4)\n",
      "Looking in indexes: http://10.100.0.6:8080\n",
      "Requirement already satisfied: psycopg2 in /usr/local/lib/python3.6/dist-packages (2.7.7)\n",
      "Looking in indexes: http://10.100.0.6:8080\n",
      "Requirement already satisfied: WISE-PaaS-DataHub-Edge-Python-SDK in /usr/local/lib/python3.6/dist-packages (1.1.4)\n",
      "Requirement already satisfied: paho-mqtt==1.4.0 in /usr/local/lib/python3.6/dist-packages (from WISE-PaaS-DataHub-Edge-Python-SDK) (1.4.0)\n",
      "Looking in indexes: http://10.100.0.6:8080\n",
      "Requirement already satisfied: func_timeout in /usr/local/lib/python3.6/dist-packages (4.3.0)\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "get_ipython().system(' pip install --default-timeout=180 boto')\n",
    "get_ipython().system(' pip install --default-timeout=180 pymongo')\n",
    "get_ipython().system(' pip install --default-timeout=180 pymssql')\n",
    "get_ipython().system(' pip install --default-timeout=180 psycopg2')\n",
    "get_ipython().system(' pip install --default-timeout=180 WISE-PaaS-DataHub-Edge-Python-SDK')\n",
    "get_ipython().system(' pip install --default-timeout=180 func_timeout')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import boto\n",
    "import boto.s3.connection\n",
    "from boto.s3.key import Key \n",
    "\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "import urllib.parse\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "import sqlite3\n",
    "import struct     \n",
    "import tempfile\n",
    "import csv\n",
    "import binascii\n",
    "import sys\n",
    "import inspect\n",
    "import pymssql\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from func_timeout import func_timeout, FunctionTimedOut\n",
    "from pymongo import MongoClient, DESCENDING\n",
    "\n",
    "#PostgreSQL access\n",
    "import psycopg2\n",
    "import pandas.io.sql as sqlio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wisepaasdatahubedgesdk.EdgeAgent import EdgeAgent\n",
    "from wisepaasdatahubedgesdk.Model.Edge import EdgeAgentOptions, MQTTOptions, DCCSOptions, NodeConfig, EdgeConfig\n",
    "from wisepaasdatahubedgesdk.Model.Edge import DeviceConfig, AnalogTagConfig, EdgeData, EdgeTag, TextTagConfig\n",
    "import wisepaasdatahubedgesdk.Common.Constants as constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scada_info = \\\n",
    "# [{'Scada project': 'Y4_FOMOS_1HSM',\n",
    "# 'Credential Key': '50099a2bb15fa8eb93b05261ef3d6dm5',\n",
    "# 'DCCS API Url': 'https://api-dccs.fomos.csc.com.tw/'}\n",
    "# ,{\n",
    "# 'Scada project': 'Y4_FOMOS_1HSM',\n",
    "# 'Credential Key': 'a4e194df77fdbbf2ccf56a9f6632bfwk',\n",
    "# 'DCCS API Url': 'https://api-dccs.fomos.csc.com.tw/'}\n",
    "# ,{\n",
    "# 'Scada project': 'Y4_FOMOS_1HSM',\n",
    "# 'Credential Key': '3fcbd86c8edd234bfc1129629f36aetw',\n",
    "# 'DCCS API Url': 'https://api-dccs.fomos.csc.com.tw/'}\n",
    "# ,{\n",
    "# 'Scada project': 'Y4_FOMOS_1HSM',\n",
    "# 'Scada name': '122',\n",
    "# 'Credential Key': '9218fd01dbe29dabab2002fe6f34e4ie',\n",
    "# 'DCCS API Url': 'https://api-dccs.fomos.csc.com.tw/'}\n",
    "# ,{\n",
    "# 'Scada project': 'Y4_FOMOS_1HSM',\n",
    "# 'Scada name': 'vpodpro',\n",
    "# 'Credential Key': '74932c8f872342d643cb73d890a5aebe',\n",
    "# 'DCCS API Url': 'https://api-dccs.fomos.csc.com.tw/'}]\n",
    "# scada_info = pd.DataFrame(scada_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'dccs_key' not in os.environ:\n",
    "#      os.environ['dccs_key'] = '50099a2bb15fa8eb93b05261ef3d6dm5'\n",
    "\n",
    "if 'scada_id' not in os.environ:\n",
    "     os.environ['scada_id'] = '14d267b3-b03c-48d3-9b54-5ca79d0c457b'\n",
    "\n",
    "if 'scada_name' not in os.environ:\n",
    "    os.environ['scada_name'] = '111'\n",
    "    \n",
    "if 'from' not in os.environ:\n",
    "    os.environ['from'] = '2020-12-01'\n",
    "    \n",
    "if 'to' not in os.environ:\n",
    "    today_twd = datetime.datetime.now() + datetime.timedelta(hours=8)\n",
    "    os.environ['to'] = today_twd.strftime('%Y-%m-%d')\n",
    "    \n",
    "if 'points' not in os.environ:\n",
    "    os.environ['points'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True if write to SCADA\n",
    "bWrite2Scada = True\n",
    "\n",
    "# True if write to SCADA and Mongodb\n",
    "bForceExtract = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mgdb_host = '10.100.10.1'\n",
    "mgdb_port = '27017'\n",
    "mgdb_username = '0c1e58e3-8643-4ff3-8633-7820f10f4902'\n",
    "mgdb_password = 'SPRXaEL2RIIeve2lsHV9oAjCc'\n",
    "mgdb_database = 'd21d5987-3b65-4fae-9b02-79f72b39b735'\n",
    "mgdb_collection = 'y4_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yesterday = datetime.datetime.today() - datetime.timedelta(days=1)\n",
    "\n",
    "# year = yesterday.strftime('%Y')\n",
    "# month = yesterday.strftime('%m')\n",
    "# day = yesterday.strftime('%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_KEY = 't7user1'\n",
    "SECRET_KEY = 'Bhw0MdOHfFL9h03u3epl4AoLxl/sOu0UvELUBL1h'\n",
    "HOST = 'object.csc.com.tw'    #172.16.247.234\n",
    "PORT = 9020\n",
    "BUCKET_NAME = 'Y4_HSM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PG_IP = \"192.168.123.238\"\n",
    "PG_USER = \"6e6b8fc2-ea3d-412e-9806-692a4aea5c0e\"\n",
    "PG_PASS = \"huu1enrd9rrsptr86kvapqk4pe\"\n",
    "PG_DB = \"214c2b8f-c62b-4133-82a8-93eb2dc59277\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datahub\n",
    "DHB_MQTT_HOST = '10.10.0.14'\n",
    "DHB_MQTT_PORT = 1883\n",
    "DHB_MQTT_USER = \"6d657c0a-7fc9-44be-b220-819efb23fbdb:403e3cd7-92ef-457b-9309-64970864bde5\"\n",
    "DHB_MQTT_PASS = \"u3s9tqk0bvn9sklt6dr8j1jpe9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_connection = boto.connect_s3(\n",
    "                   aws_access_key_id = ACCESS_KEY,\n",
    "                   aws_secret_access_key = SECRET_KEY,\n",
    "                   host = HOST,\n",
    "                   port = PORT,\n",
    "                   is_secure=False,               # uncomment if you are not using ssl\n",
    "                   calling_format = boto.s3.connection.OrdinaryCallingFormat(),\n",
    "                 )\n",
    "bucket = s3_connection.get_bucket(BUCKET_NAME, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host = PG_IP,\n",
    "    database = PG_DB,\n",
    "    user = PG_USER,\n",
    "    password = PG_PASS)\n",
    "\n",
    "sql = r'SELECT * FROM \"CSC_FOMOS\".\"Y4_Channel_List\";'\n",
    "tag_list_pd = sqlio.read_sql_query(sql, conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scada_project = 'Y4_FOMOS_1HSM'\n",
    "scada_name = os.environ['scada_name']\n",
    "scada_id = os.environ['scada_id']\n",
    "\n",
    "device_name_list = list(tag_list_pd[tag_list_pd['smartboxID'] == scada_name]['channel_name'])\n",
    "device_id_list = list(tag_list_pd[tag_list_pd['smartboxID'] == scada_name]['channelID'])\n",
    "\n",
    "# for development\n",
    "device_range = int(os.environ['points'])\n",
    "device_name_list = device_name_list[0:device_range]\n",
    "device_id_list = device_id_list[0:device_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('scada_project=',scada_project, '\\n', \n",
    "#       'scada_name=',scada_name, '\\n',\n",
    "#      'device_name=',device_name_list[0],'\\n',\n",
    "#      'device_id=',device_id_list[0],'\\n',\n",
    "#      'scada_id=',scada_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected OK Returned code= 0\n",
      "subscribe /wisepaas/scada/14d267b3-b03c-48d3-9b54-5ca79d0c457b/ack successfully\n",
      "subscribe /wisepaas/scada/14d267b3-b03c-48d3-9b54-5ca79d0c457b/cmd successfully\n",
      "subscribe successfully\n",
      "subscribe successfully\n",
      "Connected OK Returned code= 0\n",
      "subscribe /wisepaas/scada/14d267b3-b03c-48d3-9b54-5ca79d0c457b/ack successfully\n",
      "subscribe /wisepaas/scada/14d267b3-b03c-48d3-9b54-5ca79d0c457b/cmd successfully\n",
      "subscribe successfully\n",
      "subscribe successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for device_id in device_id_list:\n",
    "    \n",
    "    options = EdgeAgentOptions(\n",
    "        reconnectInterval = 1, # MQTT reconnect interval seconds\n",
    "        nodeId = scada_id, # Getting from SCADA portal\n",
    "        deviceId = device_id, # If type is Device, DeviceId must be filled\n",
    "        type = constant.EdgeType['Gateway'], # Choice your edge is Gateway or Device, Default is Gateway\n",
    "        heartbeat = 60, # Default is 60 seconds\n",
    "        dataRecover = False, # Need to recover data or not when disconnected\n",
    "        connectType = constant.ConnectType['MQTT'], # Connection type (DCCS, MQTT), default is DCCS\n",
    "        \n",
    "        MQTT = MQTTOptions( # If connectType is MQTT, must fill this options\n",
    "            hostName = DHB_MQTT_HOST,\n",
    "            port = DHB_MQTT_PORT,\n",
    "            userName = DHB_MQTT_USER,\n",
    "            password = DHB_MQTT_PASS,\n",
    "            protocalType = constant.Protocol['TCP'] # MQTT protocal (TCP, Websocket), default is TCP\n",
    "        )\n",
    "    )\n",
    "\n",
    "    edgeAgent = EdgeAgent( options = options )\n",
    "    edgeAgent.connect()\n",
    "    #Add 2020/6/13\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_binfile (new_filename, signal, dtype='f'):\n",
    "    \n",
    "    # vPorPRO_only\n",
    "    \n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "    \n",
    "    float_array = signal.astype(dtype).flatten()\n",
    "    data = struct.pack(dtype*float_array.shape[0], *float_array)\n",
    "\n",
    "    f = open(new_filename.encode('utf-8'),'wb')\n",
    "    int_array = np.array(signal.shape).reshape(1,-1).flatten()\n",
    "    siz_data = struct.pack('i'*int_array.shape[0], *int_array)\n",
    "    f.write(siz_data)\n",
    "    f.write(data)    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_binfile (filename, dtype='f'):\n",
    "    \n",
    "    # vPorPRO_only\n",
    "    \n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "    #example: \n",
    "    # signal = read_bin('Raw Data-1-1Y510110100-00-03-15.bin'); \n",
    "    # import matplotlib.pyplot as plt; plt.plot(signal.T); \n",
    "    # plt.show()\n",
    "    # import binascii\n",
    "    # import numpy as np\n",
    "\n",
    "    def hexint(b, bReverse=True): return int(binascii.hexlify(b[::-1]), 16) if bReverse else int(binascii.hexlify(b), 16)    \n",
    "    bytes_read = open(filename, \"rb\").read()\n",
    "    \n",
    "    #read matrix size, 4-byte unit\n",
    "    size = [hexint(bytes_read[(i*4):((i+1)*4)]) for i in range(2)]\n",
    "    # print(size)\n",
    "    \n",
    "    # import struct\n",
    "    signal = [struct.unpack(dtype,bytes_read[(i*4):((i+1)*4)]) for i in range(2, 2+size[0]*size[1])]\n",
    "    \n",
    "    return np.array(signal).reshape(size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s3_upload (bucket_, key, testfile): \n",
    "    \n",
    "    # vPorPRO_only\n",
    "    \n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "\n",
    "    def percent_cb(complete, total):\n",
    "        sys.stdout.write('.')\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    k = Key(bucket_)\n",
    "    k.key = key\n",
    "    \n",
    "    print(testfile.encode('utf-8'))\n",
    "    print(type(testfile))\n",
    "    \n",
    "    k.set_contents_from_filename(testfile.decode('utf-8'), cb=percent_cb, num_cb=10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_bin_from_1db (filename, bucket, mv2g=10, one_unit=8, fs=25600):\n",
    "    \n",
    "    # vPorPRO_only\n",
    "    \n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "\n",
    "    \n",
    "#     if opts is not None:\n",
    "#         smartboxID = opts['smartboxID']\n",
    "#         ScadaID = opts['ScadaID']\n",
    "#         scada_project = opts['scada_project']\n",
    "#         scada_name = opts['scada_name']\n",
    "#         scada_id = opts['scada_id']\n",
    "#         device_name = opts['device_name']\n",
    "#         device_id = opts['device_id'] \n",
    "#         bucket = opts['bucket']\n",
    "#         tag_list_pd = opts['tag_list_pd']\n",
    "#     print('*****{} connect to the DB.'.format(datetime.datetime.strftime(\\\n",
    "#                     datetime.datetime.now(),'%Y-%m-%d %H:%M:%S.%f')))\n",
    "    bucket = s3_conn()\n",
    "    sql_conn = sqlite3.connect(filename.decode('utf-8'))\n",
    "    \n",
    "    #check index for debugging purposes\n",
    "    if True:\n",
    "#         print('*****{} check index.'.format(datetime.datetime.strftime(datetime.datetime.now(),'%Y-%m-%d %H:%M:%S.%f')))\n",
    "        indices = sql_conn.execute(\"PRAGMA INDEX_LIST('records')\")\n",
    "        point_record_colnames = list(map(lambda x: x[0], indices.description))\n",
    "        point_record_row = indices.fetchone()\n",
    "        \n",
    "        if point_record_row is None: #create indices\n",
    "#             print('*****{} create index.'.format(datetime.datetime.strftime(datetime.datetime.now(),'%Y-%m-%d %H:%M:%S.%f')))\n",
    "            sql_conn.execute('CREATE INDEX \"\" ON \"records\" (\"point_id\" ASC)')\n",
    "        else:\n",
    "            indices = pd.DataFrame(list(point_record_row),index=point_record_colnames)\n",
    "        \n",
    "    #point_record\n",
    "#     print('*****{} retrieve data.'.format(datetime.datetime.strftime(\\\n",
    "#                     datetime.datetime.now(),'%Y-%m-%d %H:%M:%S.%f')))\n",
    "    rows = sql_conn.execute('select records.point_id,measure_time,vibration,bearing,temperature,\\\n",
    "                         raw_data,points.name from records LEFT JOIN measures on \\\n",
    "                         records.point_id = measures.point_id LEFT JOIN points on \\\n",
    "                         points.id = measures.point_id LEFT JOIN machines on \\\n",
    "                         points.machine_id = machines.id')\n",
    "\n",
    "    point_record_colnames = list(map(lambda x: x[0], rows.description))\n",
    "        \n",
    "    point_record_row = rows.fetchall()\n",
    "    \n",
    "    if len(point_record_row)>0:\n",
    "        rtb = pd.DataFrame(list(point_record_row),columns=point_record_colnames)\n",
    "    else:\n",
    "        rtb = pd.DataFrame([list(point_record_row)],columns=point_record_colnames)\n",
    "        \n",
    "    dtt = [datetime.datetime.fromtimestamp(r) for r in rtb['measure_time']]\n",
    "    rtb['timestamp'] = rtb['measure_time']\n",
    "    rtb['measure_time'] = dtt\n",
    "    \n",
    "    sql_conn.close()\n",
    "\n",
    "#     tmpfile = tempfile.TemporaryFile().name.split('\\\\')[-1] + '.bin'  \n",
    "    \n",
    "    for index, row in rtb.iterrows():\n",
    "        bytes_read = row['raw_data']\n",
    "        size = int(len(bytes_read) / one_unit)\n",
    "        signal_a = [struct.unpack('d',bytes_read[(i*one_unit):((i+1)*one_unit)]) for i in range(size)]\n",
    "        signal_a = np.array(signal_a).reshape(size) * mv2g\n",
    "        #[re.findall('[0-9]+',row['name'])[0] for index, row in rtb.iterrows()]\n",
    "        \n",
    "        rowID = re.findall('[0-9]+',row['name'])[0]\n",
    "        channel_name = '#{}內冷式ROT Roller WS_vpod'.format(rowID)\n",
    "        tag_list_row = tag_list_pd[tag_list_pd['channel_name']==channel_name]\n",
    "        device = tag_list_row['channelID'].iloc[0]\n",
    "        year = \"{:04d}\".format(row['measure_time'].year)\n",
    "        month = \"{:02d}\".format(row['measure_time'].month)\n",
    "        day = \"{:02d}\".format(row['measure_time'].day)\n",
    "        hour = \"{:02d}\".format(row['measure_time'].hour)\n",
    "        minute = \"{:02d}\".format(row['measure_time'].minute)\n",
    "        second = \"{:02d}\".format(row['measure_time'].second)\n",
    "        \n",
    "        prefix = '#1HSM/ROT/vPodPRO/{}/{}/{}/{}/'.format(channel_name,year,month,day)\n",
    "        S3_key_name = prefix + 'Raw Data-{}-{}-{}-{}_{}.bin'.format(channel_name,hour,minute,second,fs)\n",
    "        \n",
    "        #print('tmpfile=', S3_key_name.split('/')[-1])\n",
    "        tmpfile = S3_key_name.split('/')[-1]\n",
    "        #write_binfile('tmp.bin',signal_a.reshape(1,-1))\n",
    "        \n",
    "        write_binfile(tmpfile, signal_a.reshape(1,-1))\n",
    "        #read signal_a2=read_binfile('tmp.bin').flatten(); np.max(np.abs(signal_a-signal_a2))\n",
    "        \n",
    "        # TODO: ask Dr Ho the reason of this?\n",
    "        #s3_upload(bucket,S3_key_name,tmpfile)\n",
    "        \n",
    "        #extract features\n",
    "#         opts['device_name'] = channel_name\n",
    "#         opts['device_id'] = device\n",
    "        \n",
    "        #2020-09-24\n",
    "#         print('retrieve_bin_from_1db',scada_id,opts['device_name'],opts['device_id'])\n",
    "        extract_features(prefix=prefix,\n",
    "                         fs=fs,\n",
    "                         device_name=device,\n",
    "                         vibration=row['vibration'],\n",
    "                         bearing=row['bearing'],\n",
    "                         temperature=row['temperature'],\n",
    "                         opts=None)\n",
    "        \n",
    "    #delete tmp files\n",
    "    os.remove(tmpfile.encode('utf-8'))  \n",
    "    \n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_bin_from_dbs (src='RAW_DB', dest='RAW_DB_BACK', opts=None):\n",
    "    \n",
    "    # vPorPRO_only\n",
    "    \n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "    \n",
    "#     if opts is not None:\n",
    "#         smartboxID = opts['smartboxID']\n",
    "#         ScadaID = opts['ScadaID']\n",
    "#         scada_project = opts['scada_project']\n",
    "#         scada_name = opts['scada_name']\n",
    "#         scada_id = opts['scada_id']\n",
    "#         device_name = opts['device_name']\n",
    "#         device_id = opts['device_id'] \n",
    "#         bucket = opts['bucket']\n",
    "    \n",
    "    bucket = s3_conn()\n",
    "    prefix_ = '#1HSM/ROT/vPodPRO/'+src+'/'\n",
    "    back_prefix = '#1HSM/ROT/vPodPRO/'+dest+'/'\n",
    "    db_keys = [key for key in bucket.list(prefix=prefix_) if len(re.findall('.db$',key.name))>0]\n",
    "    \n",
    "#     print(db_keys)\n",
    "    \n",
    "    #filename = 'tmpp.db'\n",
    "#     filename = tempfile.TemporaryFile().name.split('\\\\')[-1] + '.db'\n",
    "    for db_key in db_keys: \n",
    "        \n",
    "#         print(str(db_key).split('/')[-1].split('>')[0])\n",
    "\n",
    "        filename = str(db_key).split('/')[-1].split('>')[0].encode('utf-8')\n",
    "    \n",
    "        db_key.get_contents_to_filename(filename)\n",
    "        retrieve_bin_from_1db(filename,bucket)\n",
    "        dest_name = db_key.name.replace('RAW_DB',dest)\n",
    "        db_key.copy(bucket,dest_name)\n",
    "        db_key.delete()\n",
    "        os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_ts (objs, \n",
    "                 filename,\n",
    "                 type ='tdms'):    \n",
    "\n",
    "    #print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "    \n",
    "    year = int(objs.split('/')[-4])\n",
    "    month = int(objs.split('/')[-3])\n",
    "    day = int(objs.split('/')[-2])\n",
    "    hour = int(filename.split('-')[-3])\n",
    "    minute = int(filename.split('-')[-2])\n",
    "    \n",
    "    if type=='tdms':\n",
    "        second = int(filename.split('-')[-1].split('.')[0])\n",
    "        \n",
    "    if type=='bin':\n",
    "        second = int(filename.split('-')[-1].split('_')[0])        \n",
    "        \n",
    "    #ts = datetime.datetime(year, month, day, hour, minute, second).strftime('%s')\n",
    "    ts = datetime.datetime(year, month, day, hour, minute, second).timestamp()\n",
    "    \n",
    "    return int(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_mgdb (data_dict):\n",
    "    \n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "    \n",
    "    client = MongoClient('mongodb://%s:%s@%s/%s' % (mgdb_username, mgdb_password, mgdb_host, mgdb_database))\n",
    "\n",
    "    db = client[mgdb_database]\n",
    "    collection = db[mgdb_collection]    \n",
    "    \n",
    "    for i in data_dict:\n",
    "        if \".\" in i:\n",
    "            data_dict[i.replace(\".\", \"$\")] = data_dict.pop(i)\n",
    "    \n",
    "    #filter_dict = {'RMS_WDEC0': data_dict['RMS_WDEC0']}\n",
    "    filter_dict = {\"device\" : data_dict[\"device\"], \"timestamp\" : data_dict[\"timestamp\"]}\n",
    "    update_dict = {'$set': data_dict}\n",
    "    \n",
    "    doc = collection.update_one( filter_dict, update_dict,  upsert=True)\n",
    "    #print(dir(doc))\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_mgdb (date_from, date_to, device_id):\n",
    "    \n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "\n",
    "    client = MongoClient('mongodb://%s:%s@%s/%s' % (mgdb_username, mgdb_password, mgdb_host, mgdb_database))\n",
    "    \n",
    "    gt = int(datetime.datetime.strptime(date_from + ' 0:0:0' , '%Y-%m-%d %H:%M:%S').timestamp())\n",
    "    lt = int(datetime.datetime.strptime(date_to + ' 23:59:59', '%Y-%m-%d %H:%M:%S').timestamp())\n",
    "    \n",
    "    db = client[mgdb_database]\n",
    "    collection = db[mgdb_collection]\n",
    "    \n",
    "    validation_df = pd.DataFrame(list(collection.find({ \n",
    "        '$and': [ \n",
    "            { 'timestamp': {'$gt':gt, '$lt': lt} }, \n",
    "            { 'device': device_id } ] })))\n",
    "    \n",
    "    # if MongoDB has no data, use the updated data, owen add this at 2020-05-29\n",
    "    if len(validation_df) == 0:\n",
    "        mgb_last_list = list(collection.find({ 'device':device_id }).sort('timestamp', DESCENDING).limit(10))\n",
    "        \n",
    "        if len(mgb_last_list)>0:\n",
    "            print(datetime.datetime.now(), '| got 0 documents from mongodb, use old data:', mgb_last_list[0]['timestamp'])\n",
    "            validation_df = pd.DataFrame(list(collection.find({ 'device':device_id }).sort('timestamp', DESCENDING).limit(10)))\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        print(datetime.datetime.now(), '| more than one points in MongoDB')\n",
    "\n",
    "    client.close()\n",
    "    \n",
    "    return validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_mgdb_stime (dt, device_id):\n",
    "    \n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "\n",
    "    client = MongoClient('mongodb://%s:%s@%s/%s' % (mgdb_username, mgdb_password, mgdb_host, mgdb_database))\n",
    "    \n",
    "    #dt = int(datetime.datetime.strptime(date_from + ' 0:0:0' , '%Y-%m-%d %H:%M:%S').timestamp())\n",
    "    \n",
    "    db = client[mgdb_database]\n",
    "    collection = db[mgdb_collection]\n",
    "    \n",
    "    validation_df = pd.DataFrame(list(collection.find({ \n",
    "        '$and': [ \n",
    "            { 'timestamp': dt }, \n",
    "            { 'device': device_id } ] })))\n",
    "    \n",
    "    client.close()\n",
    "    \n",
    "    # if MongoDB has no data, return False\n",
    "    if len(validation_df) == 0:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_mgdb_dt (date_from, date_to):\n",
    "    \n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "\n",
    "    client = MongoClient('mongodb://%s:%s@%s/%s' % (mgdb_username, mgdb_password, mgdb_host, mgdb_database))\n",
    "    \n",
    "    gt = int(datetime.datetime.strptime(date_from + ' 0:0:0' , '%Y-%m-%d %H:%M:%S').timestamp())\n",
    "    lt = int(datetime.datetime.strptime(date_to + ' 23:59:59', '%Y-%m-%d %H:%M:%S').timestamp())\n",
    "    \n",
    "    db = client[mgdb_database]\n",
    "    collection = db[mgdb_collection]\n",
    "    \n",
    "    validation_df = pd.DataFrame(list(collection.find({ \n",
    "        '$and': [ \n",
    "            { 'timestamp': {'$gt': gt}}, \n",
    "            { 'timestamp': {'$lt': lt }} ]\n",
    "    })))\n",
    "    \n",
    "    # if MongoDB has no data, use the updated data, owen add this at 2020-05-29\n",
    "    if len(validation_df) == 0:\n",
    "        mgb_last_list = list(collection.find({ 'device':device_id }).sort('timestamp', DESCENDING).limit(10))\n",
    "        \n",
    "        if len(mgb_last_list)>0:\n",
    "            print(datetime.datetime.now(), '| got 0 documents from mongodb, use old data:', mgb_last_list[0]['timestamp'])\n",
    "            validation_df = pd.DataFrame(list(collection.find({ 'device':device_id }).sort('timestamp', DESCENDING).limit(10)))\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        print(datetime.datetime.now(), '| more than one points in MongoDB')\n",
    "\n",
    "    client.close()\n",
    "    \n",
    "    return validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "WS_HOST = '172.16.247.48'\n",
    "WS_PORT = '54321'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSSQL_HOST = '10.20.246.188'\n",
    "MSSQL_USER = 'dioc'\n",
    "MSSQL_PASS = 'dioct16w68'\n",
    "MSSQL_DB = 'FOMOS_AI_SERVER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_features (filename, prefix, scada_name,fs=-1):\n",
    "    \n",
    "#     print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "#     import urllib.parse\n",
    "#     import requests\n",
    "#     import json\n",
    "    \n",
    "#     ip = '172.16.247.48'\n",
    "#     port = '54321'\n",
    "    \n",
    "    filename = urllib.parse.unquote(filename)\n",
    "    filename = filename.replace(' ', '%20')\n",
    "    filename = filename.replace('#', '%23')\n",
    "    \n",
    "    prefix = prefix.replace('#', '%23')\n",
    "\n",
    "    app_args = ''\n",
    "    if False:\n",
    "        app_args = '&host={}&port={}&bucket={}&accessKey={}&secretKey={}'.format(\\\n",
    "                    HOST,PORT,BUCKET_NAME,ACCESS_KEY,SECRET_KEY)\n",
    "    \n",
    "    if scada_name.lower()=='vpodpro':#not finished yet!\n",
    "        app_args1 = '&SamplingRate={}'.format(fs)\n",
    "        url = 'http://'+WS_HOST+':'+WS_PORT+'/ExtractFeatureS3BIN?key='+prefix+filename+app_args1\n",
    "    else:\n",
    "        url = 'http://'+WS_HOST+':'+WS_PORT+'/ExtractFeatureS3TDMS?key='+prefix+filename+app_args\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    data_json = json.loads(r.text)\n",
    "    \n",
    "    return data_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scada_client (data_dict):\n",
    "    \n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "#     from wisepaasdatahubedgesdk.EdgeAgent import EdgeAgent\n",
    "#     from wisepaasdatahubedgesdk.Model.Edge import EdgeAgentOptions, MQTTOptions, DCCSOptions, NodeConfig, EdgeConfig\n",
    "#     from wisepaasdatahubedgesdk.Model.Edge import DeviceConfig, AnalogTagConfig, EdgeData, EdgeTag, TextTagConfig\n",
    "#     import wisepaasdatahubedgesdk.Common.Constants as constant\n",
    "#     import datetime\n",
    "#     import pandas as pd \n",
    "    \n",
    "#     if opts is not None:\n",
    "#         smartboxID = opts['smartboxID']\n",
    "#         ScadaID = opts['ScadaID']\n",
    "#         scada_project = opts['scada_project']\n",
    "#         scada_name = opts['scada_name']\n",
    "#         scada_id = opts['scada_id']\n",
    "#         device_name = opts['device_name']\n",
    "#         device_id = opts['device_id'] \n",
    "        \n",
    "        #if device is None: device = device_id\n",
    "#         date = opts['date']\n",
    "#         AllFOMOSStationSensorInfo = opts['AllFOMOSStationSensorInfo']\n",
    "#         FOMOSTsConstraint = opts['FOMOSTsConstraint']\n",
    "#         edgeAgent = opts['edgeAgent']\n",
    "#         bWrite2Scada = opts['bWrite2Scada']\n",
    "        \n",
    "    output_df = pd.DataFrame(list(data_dict.items()),columns = ['features','values']).T\n",
    "    output_df.columns = output_df.iloc[0]\n",
    "    output_df = output_df.drop(['features'])\n",
    "    output_df = output_df.drop(columns=['type'])\n",
    "    output_df = output_df.drop(columns=['device'])\n",
    "    output_df = output_df.drop(columns=['timestamp'])\n",
    "    output_df = output_df.drop(columns=['scada'])\n",
    "    \n",
    "    # print('scada session #1')\n",
    "    \n",
    "    #print(data_dict['device']\n",
    "\n",
    "    \n",
    "    ## session 2\n",
    "    config = EdgeConfig()\n",
    "\n",
    "    # print('scada session #2')\n",
    "    nodeConfig = NodeConfig(#name = scada_name,\n",
    "                              #description = 'Machine Name',\n",
    "                              #description = scada_name,\n",
    "                              #primaryIP = None,\n",
    "                              #backupIP = None,\n",
    "                              #primaryPort = None,\n",
    "                              #backupPort = None,\n",
    "                              nodeType = constant.EdgeType['Device']\n",
    "                             )\n",
    "    config.node = nodeConfig\n",
    "\n",
    "    # print('scada session #3')\n",
    "    deviceConfig = DeviceConfig(id = device_id,\n",
    "                                name = device_name,\n",
    "                                #comPortNumber = None,\n",
    "                                deviceType = 'Device Type',\n",
    "                                #description = 'w46 Device',\n",
    "                                description = device_name\n",
    "                                #ip = None,\n",
    "                                #port = None\n",
    "                               )\n",
    "    config.node.deviceList.append(deviceConfig)\n",
    "\n",
    "    # print('scada session #4')\n",
    "    for feature in list(output_df):\n",
    "    #     textTag = TextTagConfig(name = feature ,\n",
    "    #                             description = feature ,\n",
    "    #                             readOnly = True, \n",
    "    #                             arraySize = 0)\n",
    "        analogTag = AnalogTagConfig(name = feature,\n",
    "                                    description = feature,\n",
    "                                    readOnly = False,\n",
    "                                    arraySize = 0,\n",
    "                                    spanHigh = 100000000000000000000000000000,\n",
    "                                    spanLow = -100000000000,\n",
    "                                    engineerUnit = '',\n",
    "                                    #engineerUnit = None,\n",
    "                                    integerDisplayFormat = 30,\n",
    "                                    fractionDisplayFormat = 40\n",
    "                                    )\n",
    "\n",
    "        config.node.deviceList[0].analogTagList.append(analogTag)\n",
    "\n",
    "    result = edgeAgent.uploadConfig(constant.ActionType['Create'], edgeConfig = config)\n",
    "    \n",
    "\n",
    "    # print('scada session #5')\n",
    "    #print(output_df)\n",
    "    edgeData = EdgeData()\n",
    "    for feature in list(output_df):\n",
    "        #edgeData = EdgeData()\n",
    "        deviceID = device_id\n",
    "        tagName = feature\n",
    "        #print(\"===================================\")\n",
    "        #print(output_df[feature].tail(1).values[0])\n",
    "        value = float(output_df[feature].tail(1).values[0])\n",
    "        value = \"%.2f\" % round(value, 2)\n",
    "        \n",
    "#         print(value)\n",
    "        tag = EdgeTag(deviceID,tagName,value)\n",
    "        edgeData.tagList.append(tag)\n",
    "        #print(\"===================================\")\n",
    "        #print(deviceID,tagName,value)\n",
    "        #print(\"===================================\")\n",
    "        #print(edgeData)\n",
    "        #print(len(str(value)))\n",
    "        #print(\"===================================\")\n",
    "        #print(tag)\n",
    "        # print('scada session #5-1')\n",
    "        #result = edgeAgent.sendData(data=edgeData)\n",
    "        # print('scada session #5-2')\n",
    "        #time.sleep(1)\n",
    "\n",
    "#     print(datetime.datetime.now(), '|',\n",
    "#           inspect.getframeinfo(inspect.currentframe()).function, '| Scada send data')\n",
    "    edgeData.timestamp = datetime.datetime.fromtimestamp(data_dict['timestamp']) - datetime.timedelta(hours=8)\n",
    "    \n",
    "#     print('edge datetime', datetime.datetime.fromtimestamp(data_dict['timestamp']) - datetime.timedelta(hours=8))\n",
    "    \n",
    "    print(datetime.datetime.now(), '|',\n",
    "          inspect.getframeinfo(inspect.currentframe()).function, '| send data, edge datetime',\n",
    "          datetime.datetime.fromtimestamp(data_dict['timestamp']) - datetime.timedelta(hours=8))\n",
    "    \n",
    "    result = edgeAgent.sendData(data=edgeData)\n",
    "\n",
    "# for objects in bucket.list(prefix='tdms/'): \n",
    "# for objects in bucket.list(prefix='線一/'): \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_rpms_from_FOMOS(signalid,\n",
    "#                         db,\n",
    "#                         start_date=None,\n",
    "#                         end_date=None,\n",
    "#                         tb_suffix='',\n",
    "#                         ret_ids=[1,5,20],\n",
    "#                         ret_names=['Acc RMS','Vel RMS','RPM']):\n",
    "    \n",
    "#     print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "    \n",
    "#     #get rpm information from FOMOS DB, no timeout\n",
    "#     #example: a = get_all_station_signals(server='10.20.246.188'); \n",
    "#     #         a = a=get_rpms_from_FOMOS(10,'PXI 111','2020-08-17','2020-08-17')\n",
    "#     #         a = get_rpms_from_FOMOS(a['signalid'].iloc[61],a['db_name'].iloc[61],start_date='2020-08-19',end_date='2020-08-20')\n",
    "# #     import pymssql\n",
    "# #     import datetime\n",
    "# #     import numpy as np\n",
    "# #     import csv\n",
    "# #     import pandas as pd\n",
    "    \n",
    "#     if start_date is None or end_date is None:\n",
    "#         end_date = '{:%Y-%m-%d}'.format(datetime.datetime.today())\n",
    "#         start_date = '{:%Y-%m-%d}'.format(datetime.datetime.today() - datetime.timedelta(days=1))  \n",
    "        \n",
    "# #     print('Data range: {}~{}'.format(start_date,end_date))\n",
    "#     print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function, '| Data range:', 'from:', start_date, ' to', end_date)\n",
    "    \n",
    "    \n",
    "#     conn_str = 'DRIVER={{SQL Server}};SERVER={};DATABASE={};UID={};PWD={};CHARSET=UTF8'.format(MSSQL_HOST,\n",
    "#                                                                                                db,\n",
    "#                                                                                                MSSQL_USER,\n",
    "#                                                                                                MSSQL_PASS)\n",
    "#     print('Connection string: {}'.format(conn_str))\n",
    "#     print(datetime.datetime.now(), '| MSSQL')\n",
    "    \n",
    "#     conn = pymssql.connect(conn_str,unicode_results=True)\n",
    "#     startdate = start_date + ' 00:00:00.000'\n",
    "#     enddate = end_date + ' 23:59:59.999'    \n",
    "#     sql = \"select * from Rawdata_setting{} where signalid = {} and Data_time between '{}' and '{}' order by Data_time\".format(tb_suffix,signalid,startdate,enddate)\n",
    "# #     print('SQL command: {}'.format(sql))\n",
    "#     print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function, '| MSSQL Statement:', sql)\n",
    "    \n",
    "#     data = pd.read_sql(sql,conn)    \n",
    "#     conn.close()\n",
    "#     feas = np.array(list(csv.reader(data['parameter_id_value'])))\n",
    "    \n",
    "#     if feas.shape[0]==0: return None\n",
    "#     tmp_data = data['parameter_id_value'][0].split(',')\n",
    "#     dataids = [i for i in range(1,len(tmp_data),2)]\n",
    "#     feas = feas[:,dataids].astype(np.float)  \n",
    "    \n",
    "#     parids = [int(tmp_data[i]) for i in range(0,len(tmp_data),2)]\n",
    "#     rev_ids=[parids.index(f) for i,f in enumerate(ret_ids)]\n",
    "#     data.drop(columns=['parameter_id_value'],inplace=True)\n",
    "#     return pd.concat([data,pd.DataFrame(feas[:,rev_ids],columns=ret_names)],axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rpms_from_FOMOS1(signalid,\n",
    "                         db,\n",
    "                         start_date=None,\n",
    "                         end_date=None,\n",
    "                         tb_suffix='',\n",
    "                         ret_ids=[1,5,20],\n",
    "                         ret_names=['Acc RMS','Vel RMS','RPM'],\n",
    "                         timeout=3):\n",
    "    \n",
    "    #get rpm information from FOMOS DB with timeout\n",
    "    #example: a = get_all_station_signals(server='10.20.246.188'); \n",
    "    #         a = get_rpms_from_FOMOS1(10,'PXI 111','2020-08-17','2020-08-17')\n",
    "    #         a = get_rpms_from_FOMOS1(a['signalid'].iloc[61],a['db_name'].iloc[61],start_date='2020-08-19',end_date='2020-08-20')\n",
    "\n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "    \n",
    "    if start_date is None or end_date is None:\n",
    "        end_date = '{:%Y-%m-%d}'.format(datetime.datetime.today())\n",
    "        start_date = '{:%Y-%m-%d}'.format(datetime.datetime.today() - datetime.timedelta(days=1))  \n",
    "        \n",
    "#     print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function, '| Data range:', 'from:', start_date, ' to', end_date)\n",
    "    conn_str = 'DRIVER={{SQL Server}};SERVER={};DATABASE={};UID={};PWD={};CHARSET=UTF8'.format(MSSQL_HOST,\n",
    "                                                                                               db,\n",
    "                                                                                               MSSQL_USER,\n",
    "                                                                                               MSSQL_PASS)\n",
    "#     print(datetime.datetime.now(), '| MSSQL connection:', conn_str)\n",
    "    \n",
    "    try:\n",
    "        #conn = pyodbc.connect(conn_str,unicode_results=True)\n",
    "        #conn = conn = func_timeout(timeout, pymssql.connect, args={conn_str},kwargs={'unicode_results':True})\n",
    "        conn = pymssql.connect(server=MSSQL_HOST, \n",
    "                               user=MSSQL_USER, \n",
    "                               password=MSSQL_PASS, \n",
    "                               database=db)  \n",
    "        \n",
    "    except FunctionTimedOut:\n",
    "        print ( 'Connection could not complete within {} seconds, hence terminated.'.format(timeout))\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions that doit might raise here\n",
    "        print(e)\n",
    "        return None  \n",
    "    \n",
    "    startdate = start_date + ' 00:00:00.000'\n",
    "    enddate = end_date + ' 23:59:59.999'    \n",
    "    sql = \"select * from Rawdata_setting{} where signalid = {} and Data_time between '{}' and '{}' order by Data_time\".format(tb_suffix,signalid,startdate,enddate)\n",
    "\n",
    "#     print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function, '| MSSQL Statement:', sql)\n",
    "    \n",
    "    try:\n",
    "        #data = pd.read_sql(sql,conn)   \n",
    "        data = func_timeout(timeout, pd.read_sql, args=(sql,conn))\n",
    "    except FunctionTimedOut:\n",
    "        print ( 'Query could not complete within {} seconds, hence terminated.'.format(timeout))\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions that doit might raise here\n",
    "        print(e)\n",
    "        return None \n",
    "        \n",
    "    conn.close()\n",
    "    feas = np.array(list(csv.reader(data['parameter_id_value'])))\n",
    "    if feas.shape[0]==0: return None\n",
    "    tmp_data = data['parameter_id_value'][0].split(',')\n",
    "    dataids = [i for i in range(1,len(tmp_data),2)]\n",
    "    feas = feas[:,dataids].astype(np.float)  \n",
    "    \n",
    "    parids = [int(tmp_data[i]) for i in range(0,len(tmp_data),2)]\n",
    "    rev_ids=[parids.index(f) for i,f in enumerate(ret_ids)]\n",
    "    data.drop(columns=['parameter_id_value'],inplace=True)\n",
    "    return pd.concat([data,pd.DataFrame(feas[:,rev_ids],columns=ret_names)],axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features (device_name,\n",
    "                      prefix,\n",
    "                      fs=-1,\n",
    "                      device=None,\n",
    "                      bearing=0,\n",
    "                      temperature=0,\n",
    "                      vibration=0,\n",
    "                      opts=None):\n",
    "    \n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "\n",
    "    edgeAgent = None\n",
    "    if opts is not None:\n",
    "#         smartboxID = opts['smartboxID']\n",
    "#         ScadaID = opts['ScadaID']\n",
    "#         scada_project = opts['scada_project']\n",
    "#         scada_name = opts['scada_name']\n",
    "#         scada_id = opts['scada_id']\n",
    "#         device_name = opts['device_name']\n",
    "#         device_id = opts['device_id'] \n",
    "#         if device is None: device = device_id\n",
    "\n",
    "        date = opts['date']\n",
    "        AllFOMOSStationSensorInfo = opts['AllFOMOSStationSensorInfo']\n",
    "        FOMOSTsConstraint = opts['FOMOSTsConstraint']\n",
    "        edgeAgent = opts['edgeAgent']\n",
    "#         bWrite2Scada = opts['bWrite2Scada']        \n",
    "#         bForceExtract = opts['bForceExtract']  \n",
    "        rpms = opts['rpms']  \n",
    "        \n",
    "    bucket = s3_conn()\n",
    "    objectss = [objects for objects in bucket.list(prefix=prefix)]\n",
    "    \n",
    "    #extract FOMOS RPM information\n",
    "    if scada_name.lower()!='vpodpro' and AllFOMOSStationSensorInfo is not None and rpms is None:        \n",
    "        srollerID = re.findall('.*#([0-9]{1,3}).*',device_name)[0]\n",
    "        find, frow = [(find,frow) for find,frow in AllFOMOSStationSensorInfo.iterrows() if \\\n",
    "                    srollerID in frow['signal_name'] and 'WS' in frow['signal_name'] and \\\n",
    "                    'Roller' in frow['signal_name']][0]\n",
    "        \n",
    "        fsignalid = frow['signalid']\n",
    "        fdb = frow['db_name']  \n",
    "        start_date = date.strftime('%Y-%m-%d')\n",
    "        end_date = start_date   \n",
    "        \n",
    "        print(fsignalid,fdb,start_date,end_date, 'get_rpm')\n",
    "        \n",
    "        rpms = get_rpms_from_FOMOS1(fsignalid,fdb,start_date,end_date)\n",
    "        if rpms is not None:\n",
    "            rpms['timestamp'] = [int(ts.to_pydatetime().timestamp()) for ts in rpms['Data_time']]\n",
    "        else:\n",
    "            rpms = pd.DataFrame([[-9999,0]],columns=['timestamp','RPM'])\n",
    "            print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function, '| Retrieve FOMOS RPM information fails, adopt a fake one.')\n",
    "        pass\n",
    "    \n",
    "    if scada_name.lower()!='vpodpro' and AllFOMOSStationSensorInfo is None and bForceExtract:\n",
    "        rpms = pd.DataFrame([[-9999,0]],columns=['timestamp','RPM'])\n",
    "        print('******{} Adopt fake FOMOS RPM information.'.format(\\\n",
    "        datetime.datetime.strftime(datetime.datetime.now(),'%Y-%m-%d %H:%M:%S.%f'))) \n",
    "        \n",
    "    for objects in objectss: \n",
    "        # translate Chinese etc. into url \n",
    "        # The URL quoting functions focus on taking program data and making it safe for use as URL components by quoting special characters and appropriately encoding non-ASCII text.\n",
    "        objs = urllib.parse.quote(objects.key)\n",
    "        bExtractSave = True\n",
    "        #two kinds of files: TDMS & db, to consider\n",
    "        #if ((scada_project == '條二' or scada_project == '線二') and ('Raw' in objs and 'index' not in objs)) or            ((scada_project == '線一') and ('Raw' in objs and 'index' not in objs and 'rolling' in objs)):\n",
    "        if 'Raw' in objs and 'index' not in objs and scada_name.lower()!='vpodpro':\n",
    "            # extract filename only\n",
    "            filename = objs.split('/')[-1]\n",
    "            #Key: #1HSM/ROT/TDMS/#10內冷式ROT Roller WS/2020/02/24/Raw Data-#10內冷式ROT Roller WS-00-09-57.tdms\n",
    "            timestamp = retrieve_ts(objs, filename)\n",
    "            new_prefix = '/'.join(objs.split('/')[:-1]) + '/'\n",
    "            #print(timestamp)\n",
    "            #there should be error handling procedure  \n",
    "            #apply FOMOS timestamp Constraint\n",
    "            #print(rpms)\n",
    "            ts_diff = np.abs(rpms['timestamp'].values-timestamp)\n",
    "            wh_min_diff = np.argmin(ts_diff)\n",
    "            \n",
    "            #print(datetime.datetime.now(), '|',\n",
    "            #      inspect.getframeinfo(inspect.currentframe()).function, '|  extracted:',\n",
    "            #      int(timestamp),\n",
    "            #      rpms['timestamp'].values[wh_min_diff],\n",
    "            #      ts_diff[wh_min_diff],\n",
    "            #      FOMOSTsConstraint)\n",
    "            \n",
    "            if ts_diff[wh_min_diff]>FOMOSTsConstraint: \n",
    "                #print(datetime.datetime.now(), '|',\n",
    "                #      inspect.getframeinfo(inspect.currentframe()).function,\n",
    "                #      '|  larger than FOMOSTsConstraint, bExtractSave=False, bypass')\n",
    "                bExtractSave = False\n",
    "                this_rpm = 0\n",
    "                data_dict = {}     \n",
    "            else:\n",
    "                print(datetime.datetime.now(), '|',\n",
    "                      inspect.getframeinfo(inspect.currentframe()).function,\n",
    "                      '|  larger than FOMOSTsConstraint, bExtractSave=True')\n",
    "                this_rpm = rpms['RPM'].iloc[wh_min_diff] \n",
    "                bExtractSave = True\n",
    "                \n",
    "            bExtractSave = bExtractSave or bForceExtract\n",
    "#             print(datetime.datetime.now(), '|',\n",
    "#                       inspect.getframeinfo(inspect.currentframe()).function, '|  bExtractSave:', bExtractSave)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #if bExtractSave: \n",
    "                \n",
    "            data_dict = query_features(filename,\n",
    "                                           prefix if filename in prefix else new_prefix, \n",
    "                                           scada_name)\n",
    "            data_dict['RPM'] = this_rpm\n",
    "                # vProdPro features\n",
    "                #data_dict['vibration'] = data_dict['Velocity RMS band 0']  \n",
    "            vibration = data_dict['Velocity RMS band 0']  \n",
    " \n",
    "        elif scada_name.lower()=='vpodpro':#not finished yet!\n",
    "            filename = objs.split('/')[-1]            \n",
    "            #Key: Key: #1HSM/ROT/vPodPRO/#1內冷式ROT Roller WS_vpod/2019/11/14/Raw Data-#1內冷式ROT Roller WS_vpod-18-24-43_25600.bin\n",
    "            timestamp = retrieve_ts(objs, filename,type='bin')\n",
    "            if fs==-1: \n",
    "                tmp = filename.split('_')[-1].split('.')\n",
    "                if len(tmp)<2: fs = 25600 \n",
    "                fs = 25600 if not tmp[0].isnumeric() else int(tmp[0])\n",
    "            #there should be error handling procedure    \n",
    "            data_dict = query_features(filename, prefix, scada_name, fs=fs)\n",
    "            data_dict['RPM'] = 0\n",
    "        else:\n",
    "            bExtractSave = False\n",
    "            \n",
    "                \n",
    "        data_dict['bearing'] = bearing\n",
    "        data_dict['temperature'] = temperature\n",
    "        data_dict['vibration'] = vibration\n",
    "        data_dict['type'] = 'unloading'\n",
    "        data_dict['device'] = device\n",
    "        data_dict['timestamp'] = int(timestamp)\n",
    "        data_dict['scada'] = scada_name            \n",
    "                 \n",
    "            \n",
    "        if bExtractSave:\n",
    "            \n",
    "            \n",
    "            mgdb_device_df = mgdb_df[mgdb_df['device']==device]\n",
    "            mgdb_ts_df = mgdb_device_df[mgdb_device_df['timestamp'] == int(data_dict['timestamp'])]\n",
    "            \n",
    "            if len(mgdb_ts_df)==0:\n",
    "                \n",
    "                print(datetime.datetime.now(), '|',\n",
    "                      inspect.getframeinfo(inspect.currentframe()).function,\n",
    "                      '|  no data in MongoDB')\n",
    "                \n",
    "                \n",
    "                insert_mgdb(data_dict)        \n",
    "                scada_client(data_dict)\n",
    "                time.sleep(3)\n",
    "                \n",
    "        #if edgeAgent is not None and bWrite2Scada and bExtractSave: scada_client(data_dict)\n",
    "        #if bExtractSave and bWrite2Scada: scada_client(data_dict)\n",
    "        #if bExtractSave: time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_prefix_list (scada_project,bucket):\n",
    "    \n",
    "#     print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "    \n",
    "#     prefix_list = []\n",
    "#     for key in bucket.list(delimiter='/', prefix=scada_project):\n",
    "        \n",
    "#         if key.name.count('/')!=1:\n",
    "\n",
    "#             for j in bucket.list(delimiter='/', prefix=key.name):\n",
    "#                 if j.name.count('/')!=2:\n",
    "#                     prefix_list.append(j.name)\n",
    "                     \n",
    "#     return prefix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def feature_extraction(date):\n",
    "    \n",
    "#     print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "\n",
    "#     # combine into S3 key\n",
    "#     if scada_name.lower()=='vpodpro':#not finished yet!\n",
    "#         prefix_ = scada_project + '/ROT/vProdPRO/RAW_DB/'\n",
    "#         retrieve_bin_from_dbs ()\n",
    "#     else:\n",
    "#         prefix_ = scada_project + '/ROT/TDMS/' + device_name + '/'        \n",
    "#         #should single_date -> date ??\n",
    "#         year = \"{:04d}\".format(date.year)\n",
    "#         month = \"{:02d}\".format(date.month)\n",
    "#         day = \"{:02d}\".format(date.day)\n",
    "        \n",
    "#         # variable 'extract_features' specifies which day begining to extract features.\n",
    "#         extraction_anchor = prefix_ + str(year) + '/' + str(month) + '/' + str(day) + '/'\n",
    "#         extract_features (device_name, \n",
    "#                           extraction_anchor,\n",
    "#                           device=device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signal_names (StationName='111'):  \n",
    "    \n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "#     import pandas as pd\n",
    "#     import pymssql\n",
    "    #example: GetSignalNames(StationName='112',server='10.20.246.145')\n",
    "    StationNames = get_station_names()\n",
    "    \n",
    "    if not (StationName in StationNames['client_name'].tolist()): \n",
    "        print('Station {} is not in {}'.format(StationName,server))\n",
    "        return None\n",
    "    \n",
    "    db = StationNames[StationNames['client_name']==StationName]['db_name'].iloc[0]\n",
    "    conn = pymssql.connect(server=MSSQL_HOST, \n",
    "                           user=MSSQL_USER, \n",
    "                           password=MSSQL_PASS, \n",
    "                           database=db)   \n",
    "    \n",
    "    sql = 'select * from signal_ID'\n",
    "    data = pd.read_sql(sql,conn)\n",
    "    conn.close()\n",
    "    return data\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def get_all_station_signals ():\n",
    "    \n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "#     import pandas as pd\n",
    "    \n",
    "    #example: signals=get_all_station_signals(); signals.index=range(signals.shape[0]); signals.to_csv('signals.csv',encoding='utf-8-sig')\n",
    "    StationNames = get_station_names()\n",
    "    ress = []\n",
    "    for i in range(StationNames.shape[0]):\n",
    "        StationName = StationNames['client_name'].iloc[i]\n",
    "        Info = StationNames.iloc[i,:]\n",
    "        SignalNames = get_signal_names (StationName=StationName)[['signalid','signal_name','channel_ID']]\n",
    "        res = pd.concat([pd.DataFrame(Info.values.reshape(1,-1).repeat(SignalNames.shape[0],axis=0),columns=Info.index.tolist()),SignalNames],axis=1)\n",
    "        ress.append(res)\n",
    "    result = pd.concat(ress)\n",
    "    result.index=range(result.shape[0])\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_station_names():\n",
    "    \n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "#     import pymssql\n",
    "#     import pandas as pd \n",
    "    \n",
    "    #example: get_station_names(server='10.20.246.145')\n",
    "    #conn = pymssql.connect('DRIVER={{SQL Server}};SERVER={};DATABASE={};UID={};PWD={}'.format(server,db,uid,pwd))\n",
    "    conn = pymssql.connect(server=MSSQL_HOST, \n",
    "                           user=MSSQL_USER,\n",
    "                           password=MSSQL_PASS, \n",
    "                           database=MSSQL_DB)  \n",
    "    \n",
    "    sql = 'select * from client_info'\n",
    "    data = pd.read_sql(sql,conn)\n",
    "    conn.close()\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction2 (date,opts):\n",
    "    \n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "    \n",
    "#     smartboxID = opts['smartboxID']\n",
    "#     ScadaID = opts['ScadaID']\n",
    "#     scada_project = opts['scada_project']\n",
    "#     scada_name = opts['scada_name']\n",
    "#     scada_id = opts['scada_id']\n",
    "#     device_name = opts['device_name']\n",
    "#     device_id = opts['device_id']\n",
    "    opts['date'] = date\n",
    "    #opts['AllFOMOSStationSensorInfo'] = None\n",
    "    \n",
    "    # combine into S3 key\n",
    "    if scada_name.lower()=='vpodpro':#not finished yet!\n",
    "        prefix_ = '#1HSM/ROT/vProdPRO/RAW_DB/'\n",
    "        retrieve_bin_from_dbs (opts=opts)\n",
    "    else:\n",
    "        if opts['AllFOMOSStationSensorInfo'] is None:\n",
    "#             print('******{} retrieve FOMOS sensor list.'.format(\\\n",
    "#             datetime.datetime.strftime(datetime.datetime.now(),'%Y-%m-%d %H:%M:%S.%f'))) \n",
    "            \n",
    "            print(datetime.datetime.now(), '| Retrieve FOMOS sensor list')\n",
    "            \n",
    "            AllFOMOSStationSensorInfo = get_all_station_signals()\n",
    "            opts['AllFOMOSStationSensorInfo'] = AllFOMOSStationSensorInfo\n",
    "            \n",
    "        prefix_ = '#1HSM/ROT/TDMS/' + device_name + '/'        \n",
    "        #should single_date -> date ??\n",
    "        year = \"{:04d}\".format(date.year)\n",
    "        month = \"{:02d}\".format(date.month)\n",
    "        day = \"{:02d}\".format(date.day)\n",
    "        \n",
    "        # variable 'extract_features' specifies which day begining to extract features.\n",
    "        prefix = prefix_ + str(year) + '/' + str(month) + '/' + str(day) + '/'\n",
    "        \n",
    "        extract_features(device_name,\n",
    "                         prefix,\n",
    "                         device=device_id,\n",
    "                         opts=opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scada_conn ():\n",
    "    \n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "    \n",
    "    options = EdgeAgentOptions(\n",
    "        reconnectInterval = 1, # MQTT reconnect interval seconds\n",
    "        nodeId = scada_id, # Getting from SCADA portal\n",
    "        deviceId = device_id, # If type is Device, DeviceId must be filled\n",
    "        type = constant.EdgeType['Gateway'], # Choice your edge is Gateway or Device, Default is Gateway\n",
    "        heartbeat = 60, # Default is 60 seconds\n",
    "        dataRecover = False, # Need to recover data or not when disconnected\n",
    "        connectType = constant.ConnectType['MQTT'], # Connection type (DCCS, MQTT), default is DCCS\n",
    "        \n",
    "        MQTT = MQTTOptions( # If connectType is MQTT, must fill this options\n",
    "            hostName = DHB_MQTT_HOST,\n",
    "            port = DHB_MQTT_PORT,\n",
    "            userName = DHB_MQTT_USER,\n",
    "            password = DHB_MQTT_PASS,\n",
    "            protocalType = constant.Protocol['TCP'] # MQTT protocal (TCP, Websocket), default is TCP\n",
    "        )\n",
    "    )\n",
    "\n",
    "    edgeAgent = EdgeAgent( options = options )\n",
    "    edgeAgent.connect()\n",
    "    \n",
    "    return edgeAgent\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s3_conn():\n",
    "    \n",
    "    #print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "\n",
    "    s3_connection = boto.connect_s3(\n",
    "                       aws_access_key_id = ACCESS_KEY,\n",
    "                       aws_secret_access_key = SECRET_KEY,\n",
    "                       host = HOST,\n",
    "                       port = PORT,\n",
    "                       is_secure=False,               # uncomment if you are not using ssl\n",
    "                       calling_format = boto.s3.connection.OrdinaryCallingFormat(),\n",
    "                     )\n",
    "    bucket = s3_connection.get_bucket(BUCKET_NAME, validate=False)\n",
    "    \n",
    "    return bucket\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_to_wisepaas(\n",
    "                                FOMOSTsConstraint=120,\n",
    "                                FOMOSSensorInfo=None):\n",
    "\n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function)\n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function, '| scada_project:', scada_project)\n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function, '| scada_name:', scada_name)\n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function, '| device_id:', device_id)\n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function, '| scada_id:', scada_id)\n",
    "    \n",
    "    day_count = (datetime.datetime.strptime(os.environ['to'], '%Y-%m-%d') -\n",
    "                 datetime.datetime.strptime(os.environ['from'], '%Y-%m-%d')).days\n",
    "    today = (datetime.datetime.now().date()).strftime('%Y-%m-%d')\n",
    "    \n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function, '| dt_from:', os.environ['from'])\n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function, '| dt_to:', os.environ['to'])\n",
    "    print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function, '| dt_now:', today)\n",
    "\n",
    "\n",
    "    \n",
    "    edgeAgent = None\n",
    "    if bWrite2Scada:\n",
    "        edgeAgent = scada_conn ()\n",
    "        \n",
    "    opts = {'FOMOSTsConstraint':FOMOSTsConstraint,\n",
    "            'edgeAgent':edgeAgent,\n",
    "            'AllFOMOSStationSensorInfo':FOMOSSensorInfo,\n",
    "            'rpms':None\n",
    "           }\n",
    "#     print(opts)\n",
    "#     opts['tag_list_pd'] = sensor_list\n",
    "\n",
    "    mgdb_date_list = []\n",
    "    if not bForceExtract:\n",
    "        \n",
    "        print(datetime.datetime.now(), '|',\n",
    "              inspect.getframeinfo(inspect.currentframe()).function, '| disable bForceExtract')\n",
    "        \n",
    "        ## query mongodb\n",
    "        #temp = query_mgdb(os.environ['from'], \n",
    "        #                  os.environ['to'], \n",
    "        #                  device_id = device_id)\n",
    "        \n",
    "        temp = mgdb_df[mgdb_df['device']==device_id]\n",
    "    \n",
    "        print(datetime.datetime.now(), '|',\n",
    "              inspect.getframeinfo(inspect.currentframe()).function, '| Number of datapoints in mongodb:', len(temp))\n",
    "    \n",
    "        if temp.shape[0]>0:\n",
    "            mgdb_date_list = pd.to_datetime(temp.timestamp, unit='s').dt.strftime('%Y-%m-%d').unique().tolist()\n",
    "        ## query mongodb end\n",
    "\n",
    "    \n",
    "    \n",
    "    s3_date_list = []\n",
    "    bucket = s3_conn()\n",
    "    \n",
    "    \n",
    "    if scada_name.lower()=='vpodpro':\n",
    "        #prefix = scada_project + '/ROT/vPodPRO/RAW_DB/' + device_name + '/' + str(year) + '/' + str(month) + '/' + str(day) + '/'\n",
    "        feature_extraction2('',opts)\n",
    "        pass\n",
    "    else:\n",
    "#         for single_date in (datetime.datetime.now().date() - datetime.timedelta(n) for n in range(day_count)):\n",
    "        for single_date in (datetime.datetime.strptime(os.environ['to'], '%Y-%m-%d') - datetime.timedelta(n) for n in range(day_count)):\n",
    "\n",
    "            ## query s3\n",
    "            year = \"{:04d}\".format(single_date.year)\n",
    "            month = \"{:02d}\".format(single_date.month)\n",
    "            day = \"{:02d}\".format(single_date.day)\n",
    "\n",
    "            # combine into S3 key\n",
    "            prefix = '#1HSM/ROT/TDMS/' + device_name + '/' + str(year) + '/' + str(month) + '/' + str(day) + '/'\n",
    "            \n",
    "            #print(datetime.datetime.now(), '|',\n",
    "            #      inspect.getframeinfo(inspect.currentframe()).function,\n",
    "            #      '|  s3_prefix=', prefix)\n",
    "            \n",
    "            b_list = bucket.list(prefix=prefix)\n",
    "\n",
    "            if len(list(b_list)) > 0:\n",
    "                s3_date_list.append(single_date.strftime('%Y-%m-%d'))\n",
    "            ## query s3 end\n",
    "\n",
    "            \n",
    "        ## compare mongodb and s3\n",
    "        date_diff = list(set(s3_date_list) - set(mgdb_date_list))\n",
    "        date_diff = sorted(date_diff)\n",
    "        print(datetime.datetime.now(), '|', inspect.getframeinfo(inspect.currentframe()).function,\n",
    "              '| date_diff, mongodb list and s3 list=', len(date_diff), len(mgdb_date_list), len(s3_date_list))\n",
    "        ## compare mongodb and s3 end\n",
    "            \n",
    "        \n",
    "        if FOMOSSensorInfo is None:\n",
    "            print(datetime.datetime.now(), '|',\n",
    "                  inspect.getframeinfo(inspect.currentframe()).function, \n",
    "                  '| Retrieve FOMOS sensor list')\n",
    "        \n",
    "            FOMOSSensorInfo = get_all_station_signals()\n",
    "            opts['AllFOMOSStationSensorInfo'] = FOMOSSensorInfo\n",
    "        \n",
    "        #extract rpms information\n",
    "        if FOMOSSensorInfo is not None:\n",
    "            srollerID = re.findall('.*#([0-9]{1,3}).*',device_name)[0]\n",
    "            find, frow = [(find,frow) for find,frow in FOMOSSensorInfo.iterrows() if \\\n",
    "                        srollerID in frow['signal_name'] and 'WS' in frow['signal_name'] and \\\n",
    "                        'Roller' in frow['signal_name']][0]\n",
    "            \n",
    "            fsignalid = frow['signalid']\n",
    "            fdb = frow['db_name'] \n",
    "            \n",
    "            rpms = get_rpms_from_FOMOS1(fsignalid,\n",
    "                                        fdb,\n",
    "                                        os.environ['to'],\n",
    "                                        today)\n",
    "            \n",
    "            if rpms is not None:\n",
    "                rpms['timestamp'] = [int(ts.to_pydatetime().timestamp()) for ts in rpms['Data_time']] \n",
    "                \n",
    "            result = 'failed' if rpms is None else 'successfully'\n",
    "            print(datetime.datetime.now(), '|',\n",
    "                  inspect.getframeinfo(inspect.currentframe()).function, '| Retrieve FOMOS RPM information', result)\n",
    "            \n",
    "            opts['rpms'] = rpms\n",
    "            \n",
    "            \n",
    "        ## extraction\n",
    "        for single_date in date_diff:\n",
    "\n",
    "            print(datetime.datetime.now(), '|',\n",
    "                  inspect.getframeinfo(inspect.currentframe()).function,\n",
    "                  '| extract features date:', single_date)\n",
    "            \n",
    "            feature_extraction2(datetime.datetime.strptime(single_date, \"%Y-%m-%d\"), opts)  \n",
    "            \n",
    "            \n",
    "    if edgeAgent is not None: edgeAgent.disconnect()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-12 13:50:57.800948 | query_mgdb_dt\n",
      "2020-11-12 13:51:03.425788 | more than one points in MongoDB\n",
      "2020-11-12 13:51:03.428114 | extract_feature_to_wisepaas\n",
      "2020-11-12 13:51:03.435090 | extract_feature_to_wisepaas | scada_project: Y4_FOMOS_1HSM\n",
      "2020-11-12 13:51:03.439867 | extract_feature_to_wisepaas | scada_name: 111\n",
      "2020-11-12 13:51:03.444556 | extract_feature_to_wisepaas | device_id: Y4121110101\n",
      "2020-11-12 13:51:03.449427 | extract_feature_to_wisepaas | scada_id: 14d267b3-b03c-48d3-9b54-5ca79d0c457b\n",
      "2020-11-12 13:51:03.454793 | extract_feature_to_wisepaas | dt_from: 2020-09-01\n",
      "2020-11-12 13:51:03.459199 | extract_feature_to_wisepaas | dt_to: 2020-11-12\n",
      "2020-11-12 13:51:03.463501 | extract_feature_to_wisepaas | dt_now: 2020-11-12\n",
      "2020-11-12 13:51:03.467653 | scada_conn\n",
      "2020-11-12 13:51:03.484671 | extract_feature_to_wisepaas | disable bForceExtract\n",
      "2020-11-12 13:51:03.500006 | extract_feature_to_wisepaas | Number of datapoints in mongodb: 0\n",
      "Connected OK Returned code= 0\n",
      "subscribe /wisepaas/scada/14d267b3-b03c-48d3-9b54-5ca79d0c457b/ack successfully\n",
      "subscribe /wisepaas/scada/14d267b3-b03c-48d3-9b54-5ca79d0c457b/cmd successfully\n",
      "subscribe successfully\n",
      "subscribe successfully\n",
      "2020-11-12 13:51:13.544729 | extract_feature_to_wisepaas | date_diff, mongodb list and s3 list= 53 0 53\n",
      "2020-11-12 13:51:13.551849 | extract_feature_to_wisepaas | Retrieve FOMOS sensor list\n",
      "2020-11-12 13:51:13.556504 | get_all_station_signals\n",
      "2020-11-12 13:51:13.561616 | get_station_names\n",
      "2020-11-12 13:51:13.580421 | get_signal_names\n",
      "2020-11-12 13:51:13.587047 | get_station_names\n",
      "2020-11-12 13:51:13.624063 | get_signal_names\n",
      "2020-11-12 13:51:13.632304 | get_station_names\n",
      "2020-11-12 13:51:13.665221 | get_signal_names\n",
      "2020-11-12 13:51:13.674175 | get_station_names\n",
      "2020-11-12 13:51:13.703431 | get_signal_names\n",
      "2020-11-12 13:51:13.712089 | get_station_names\n",
      "2020-11-12 13:51:13.781519 | get_signal_names\n",
      "2020-11-12 13:51:13.790335 | get_station_names\n",
      "2020-11-12 13:51:13.819267 | get_signal_names\n",
      "2020-11-12 13:51:13.825927 | get_station_names\n",
      "2020-11-12 13:51:13.864852 | get_signal_names\n",
      "2020-11-12 13:51:13.875077 | get_station_names\n",
      "2020-11-12 13:51:13.988976 | get_rpms_from_FOMOS1\n",
      "2020-11-12 13:51:14.014429 | extract_feature_to_wisepaas | Retrieve FOMOS RPM information successfully\n",
      "2020-11-12 13:51:14.023954 | extract_feature_to_wisepaas | extract features date: 2020-09-02\n",
      "2020-11-12 13:51:14.033014 | feature_extraction2\n",
      "2020-11-12 13:51:14.043902 | extract_features\n",
      "2020-11-12 13:53:20.173586 | extract_feature_to_wisepaas | extract features date: 2020-09-03\n",
      "2020-11-12 13:53:20.201588 | feature_extraction2\n",
      "2020-11-12 13:53:20.211213 | extract_features\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mgdb_df = query_mgdb_dt(os.environ['from'], os.environ['to'])\n",
    "\n",
    "for dname, did in zip(device_name_list, device_id_list):\n",
    "    \n",
    "    device_id=did\n",
    "    device_name=dname\n",
    "    \n",
    "    extract_feature_to_wisepaas(FOMOSTsConstraint=70)\n",
    "    \n",
    "    print(datetime.datetime.now(), '|*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO1: (done) consistency function name\n",
    "# TODO2: precise comparision between S3 and MongoDB\n",
    "# TODO3: variable scada_project should be consistency\n",
    "# TODO4: remove opt\n",
    "# TODO5: split extract_features for TDMS and BIN\n",
    "# TODO6: specify datetime for vPodPRO\n",
    "# TODO7: refact flags\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
